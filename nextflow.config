includeConfig 'subworkflows/initiate_proteins/nextflow.config'
includeConfig 'subworkflows/execute_clustering/nextflow.config'
includeConfig 'subworkflows/annotate_slices/nextflow.config'

process {
    withLabel: venv {
        container = "vagkaratzas/mgnifams:latest"
    }
    withLabel: mmseqs {
        container = "quay.io/microbiome-informatics/mmseqs:2.13"
    }
    withLabel: mafft {
        container = "quay.io/biocontainers/mafft:7.520--h031d066_2"
    }
    withLabel: seqtk {
        container = "quay.io/biocontainers/seqtk:1.4--he4a0461_1"
    }
    withLabel: hmmer {
        container = "quay.io/biocontainers/hmmer:3.3.2--hdbdd923_4"
    }
    withLabel: blast {
        container = "quay.io/biocontainers/blast:2.14.1--pl5321h6f7f691_0"
    }
    withLabel: ips {
        container = "quay.io/microbiome-informatics/palidis_v3.1.2:latest"
        cpus = 8
        memory = '12.0 GB'
        // container = "quay.io/biocontainers/interproscan:5.59-91.0" // TODO remove, produces error due to missing the program pfsearchV3
    }
    withLabel: eggnog {
        container = "quay.io/microbiome-informatics/genomes-pipeline.eggnog-mapper:v2.1.11"
        cpus = 8
        memory = '12.0 GB'
    }
}

profiles {

    slurm {
        executor {
            name = "slurm"
            queueSize = 200
            queueGlobalStatus = true
        }
        workDir = "/hps/nobackup/rdf/metagenomics/service-team/users/vangelis/work/"
        // workDir = "/nfs/production/rdf/metagenomics/users/vangelis/work/"
        singularity {
            enabled = true
            pullTimeout = "3 hours"
            autoMounts = true
            cacheDir = "/hps/scratch/singularity/$USER"
        }
        process {
            queue = 'standard'
            time = '1d'
            cache = "lenient"
            cpus = 1
            memory = 6.GB
            time = 4.h
            errorStrategy = { task.exitStatus in ((130..145) + 104) ? 'retry' : 'finish' }
            maxRetries = 1
            withName: KEEP_UNANNOTATED { memory = '30.0 MB'}
            withName: EXPORT_PROTEINS_CSV { memory = '130.0 MB'}
            withName: CREATEDB { cpus = 8; memory = '30.0 GB'}
            withName: LINCLUST { cpus = 32; memory = '200.0 GB'}
            withName: CREATETSV { cpus = 8; memory = '40.0 GB'}
            withName: EXPORT_CLUSTERING_CSV { memory = '40.0 MB'}
            withName: PARSE_FAMILIES { memory = '200.0 GB'}
            withName: MAKEBLASTDB { memory = '1.3 GB'}
            withName: CLUSTERUPDATE { cpus = 32; memory = '300.0 GB'}
            withLabel: ips { cpus = 16; memory = '15.0 GB' }
            withLabel: eggnog { memory = '50.0 GB' }  // cpus = 16
        }
        params {
            mgy_dataDir = "/nfs/production/rdf/metagenomics/projects/protein_db/releases/2023_02/"
            mgy90_dataDir = "/nfs/production/rdf/metagenomics/users/vangelis/plp_flatfiles_pgsql_2/"
            dataDir = "/nfs/production/rdf/metagenomics/users/vangelis/mgnifams/data/input/"
            outDir = "/nfs/production/rdf/metagenomics/users/vangelis/mgnifams/data/output/"
            scriptDir = "${baseDir}/bin/"
        }
    }

    lsf {
        executor {
            name = "lsf"
            queueSize = 2000
            submitRateLimit = "10/1sec"
            exitReadTimeout = "30 min"
            jobName = {
                task.name // [] and " " not allowed in lsf job names
                    .replace("[", "(")
                    .replace("]", ")")
                    .replace(" ", "_")
            }
        }
        workDir = "/hps/nobackup/rdf/metagenomics/service-team/users/vangelis/work/"
        // workDir = "/nfs/production/rdf/metagenomics/users/vangelis/work/"
        singularity {
            enabled = true
            pullTimeout = "3 hours"
            autoMounts = true
            cacheDir = "/hps/scratch/singularity/$USER"
        }
        process{
            queue = {
                if ( task.time > 7.day && task.memory > 300.GB ) {
                    "long_bigmem"
                } else if ( task.memory > 300.GB ) {
                    "bigmem"
                } else if ( task.time > 7.day ) {
                    "long"
                } else if ( task.time > 1.day ) {
                    "research"
                } else {
                    "short"
                }
            }
            // this is to avoid errors for missing files due to shared filesystem latency
            maxRetries = 3
            errorStrategy = { ( task.exitStatus == 0 ) ? "retry" : "terminate" }
            cache = "lenient"
            afterScript = "sleep 60" // to avoid fail when using storeDir for missing output
            withName: CREATEDB { cpus = 8; memory = '50.0 GB'}
            withName: LINCLUST { cpus = 32; memory = '500.0 GB'}
            withName: CREATETSV { cpus = 8; memory = '50.0 GB'}
            withName: CLUSTERUPDATE { cpus = 32; memory = '500.0 GB'}
            withLabel: ips {
                cpus = 16
                memory = '15.0 GB'
            }
            withLabel: eggnog {
                // cpus = 16
                memory = '50.0 GB'
            }
        }
        params {
            mgy_dataDir = "/nfs/production/rdf/metagenomics/projects/protein_db/releases/2023_02/"
            mgy90_dataDir = "/nfs/production/rdf/metagenomics/users/vangelis/plp_flatfiles_pgsql_2/"
            dataDir = "/nfs/production/rdf/metagenomics/users/vangelis/mgnifams/data/input/"
            outDir = "/nfs/production/rdf/metagenomics/users/vangelis/mgnifams/data/output/"
            scriptDir = "${baseDir}/bin/"
        }
    }

    local {
        singularity {
            enabled = true
            autoMounts = true
            cacheDir = "/home/vangelis/Desktop/Tools/singularity"
        }
        process {
            withName: LINCLUST { cpus = 8; memory = '10.0 GB'}
            withName: CREATETSV { cpus = 8; memory = '2.0 GB'}
            withName: CLUSTERUPDATE { cpus = 8; memory = '10.0 GB'}
        }
        params {
            mgy_dataDir = "${baseDir}/data/input/"
            mgy90_dataDir = "${baseDir}/test-data/"
            dataDir = "${baseDir}/data/input/"
            outDir = "${baseDir}/data/output/"
            scriptDir = "${baseDir}/bin/"
        }
    }
}